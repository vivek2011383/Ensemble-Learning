{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11918734",
   "metadata": {},
   "source": [
    "THEORITICAL QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee6728",
   "metadata": {},
   "source": [
    "1. **Can we use Bagging for regression problems?**  \n",
    "   - Yes, Bagging can be used for regression problems. The `BaggingRegressor` in scikit-learn trains multiple regressors on bootstrap samples and aggregates predictions (e.g., by averaging).\n",
    "\n",
    "2. **What is the difference between multiple model training and single model training?**  \n",
    "   - Single model training uses one algorithm to make predictions, while multiple model training (ensemble methods) combines predictions from several models to reduce variance, bias, or improve accuracy.\n",
    "\n",
    "3. **Explain the concept of feature randomness in Random Forest.**  \n",
    "   - Random Forest introduces randomness by selecting a random subset of features at each split during tree construction. This reduces correlation between trees, improving generalization.\n",
    "\n",
    "4. **What is OOB (Out-of-Bag) Score?**  \n",
    "   - OOB score evaluates a Random Forest model using data not included in the bootstrap sample for a tree. It calculates the average error for these \"out-of-bag\" samples across all trees.\n",
    "\n",
    "5. **How can you measure the importance of features in a Random Forest model?**  \n",
    "   - Feature importance is measured by the average reduction in impurity (Gini/entropy) caused by a feature across all trees. Alternatively, permutation importance measures the drop in accuracy when a feature is shuffled.\n",
    "\n",
    "6. **Explain the working principle of a Bagging Classifier.**  \n",
    "   - A Bagging Classifier trains multiple instances of a base classifier on different bootstrap samples of the dataset. Predictions are aggregated (e.g., majority voting) for the final output.\n",
    "\n",
    "7. **How do you evaluate a Bagging Classifierâ€™s performance?**  \n",
    "   - Use metrics like accuracy, precision, recall, F1-score, or ROC-AUC. Cross-validation and OOB score (if supported) are also effective evaluation methods.\n",
    "\n",
    "8. **How does a Bagging Regressor work?**  \n",
    "   - Similar to the classifier, a Bagging Regressor trains multiple regressors on bootstrap samples and aggregates their predictions (e.g., by averaging) to produce the final output.\n",
    "\n",
    "9. **What is the main advantage of ensemble techniques?**  \n",
    "   - Ensemble techniques improve predictive performance by combining multiple models, reducing variance and/or bias, and enhancing generalization.\n",
    "\n",
    "10. **What is the main challenge of ensemble methods?**  \n",
    "    - Increased computational cost and memory usage. They are also less interpretable compared to single models.\n",
    "\n",
    "11. **Explain the key idea behind ensemble techniques.**  \n",
    "    - Combine predictions from multiple weak learners (e.g., decision trees) to create a strong learner, leveraging collective performance for better accuracy.\n",
    "\n",
    "12. **What is a Random Forest Classifier?**  \n",
    "    - An ensemble method that builds multiple decision trees using bagging and feature randomness. It aggregates predictions (majority vote) to improve accuracy and reduce overfitting.\n",
    "\n",
    "13. **What are the main types of ensemble techniques?**  \n",
    "    - The three primary types are: **Bagging** (parallel training), **Boosting** (sequential training), and **Stacking** (combining models via a meta-learner).\n",
    "\n",
    "14. **What is ensemble learning in machine learning?**  \n",
    "    - A paradigm where multiple models (e.g., classifiers or regressors) are trained and combined to achieve better performance than any individual model.\n",
    "\n",
    "15. **When should we avoid using ensemble methods?**  \n",
    "    - When computational resources are limited, when interpretability is critical, or when the base model is already optimal (e.g., low bias/variance).\n",
    "\n",
    "16. **How does Bagging help in reducing overfitting?**  \n",
    "    - By training models on diverse bootstrap samples and averaging predictions, Bagging reduces variance, a primary cause of overfitting.\n",
    "\n",
    "17. **Why is Random Forest better than a single Decision Tree?**  \n",
    "    - Random Forest reduces overfitting by averaging predictions from multiple decorrelated trees (due to feature randomness) and improves generalization.\n",
    "\n",
    "18. **What is the role of bootstrap sampling in Bagging?**  \n",
    "    - Bootstrap sampling creates diverse training subsets by sampling with replacement. This increases model diversity, which is critical for effective aggregation.\n",
    "\n",
    "19. **What are some real-world applications of ensemble techniques?**  \n",
    "    - Fraud detection, recommendation systems (e.g., Netflix), medical diagnosis, financial forecasting, and image classification.\n",
    "\n",
    "20. **What is the difference between Bagging and Boosting?**  \n",
    "    - **Bagging** trains models in parallel on bootstrap samples and aggregates results. **Boosting** trains models sequentially, focusing on errors from prior models, and combines predictions with weighted votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cc21c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916f5cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3256.9618\n"
     ]
    }
   ],
   "source": [
    "# 22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec153219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius: 0.0487\n",
      "mean texture: 0.0136\n",
      "mean perimeter: 0.0533\n",
      "mean area: 0.0476\n",
      "mean smoothness: 0.0073\n",
      "mean compactness: 0.0139\n",
      "mean concavity: 0.0680\n",
      "mean concave points: 0.1062\n",
      "mean symmetry: 0.0038\n",
      "mean fractal dimension: 0.0039\n",
      "radius error: 0.0201\n",
      "texture error: 0.0047\n",
      "perimeter error: 0.0113\n",
      "area error: 0.0224\n",
      "smoothness error: 0.0043\n",
      "compactness error: 0.0053\n",
      "concavity error: 0.0094\n",
      "concave points error: 0.0035\n",
      "symmetry error: 0.0040\n",
      "fractal dimension error: 0.0053\n",
      "worst radius: 0.0780\n",
      "worst texture: 0.0217\n",
      "worst perimeter: 0.0671\n",
      "worst area: 0.1539\n",
      "worst smoothness: 0.0106\n",
      "worst compactness: 0.0203\n",
      "worst concavity: 0.0318\n",
      "worst concave points: 0.1447\n",
      "worst symmetry: 0.0101\n",
      "worst fractal dimension: 0.0052\n"
     ]
    }
   ],
   "source": [
    "# 23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "for name, importance in zip(data.feature_names, rf.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acc3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 2952.0106\n",
      "Decision Tree MSE: 4976.7978\n"
     ]
    }
   ],
   "source": [
    "# 24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"Random Forest MSE: {mse_rf:.4f}\")\n",
    "print(f\"Decision Tree MSE: {mse_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0f68b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.9533\n"
     ]
    }
   ],
   "source": [
    "# 25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "rf.fit(X, y)\n",
    "print(f\"OOB Score: {rf.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c65800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045d6b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10: Accuracy=0.9561\n",
      "n_estimators=50: Accuracy=0.9649\n",
      "n_estimators=100: Accuracy=0.9649\n",
      "n_estimators=200: Accuracy=0.9649\n"
     ]
    }
   ],
   "source": [
    "# 27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_trees = [10, 50, 100, 200]\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"n_estimators={n}: Accuracy={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8408bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_proba = bagging.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db45b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.0575\n",
      "sex: 0.0119\n",
      "bmi: 0.2762\n",
      "bp: 0.0871\n",
      "s1: 0.0473\n",
      "s2: 0.0554\n",
      "s3: 0.0512\n",
      "s4: 0.0271\n",
      "s5: 0.3156\n",
      "s6: 0.0708\n"
     ]
    }
   ],
   "source": [
    "# 29. Train a Random Forest Regressor and analyze feature importance scores.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "for name, importance in zip(data.feature_names, rf.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91792fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9561\n",
      "Random Forest Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bag = bagging.predict(X_test)\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Bagging Accuracy: {acc_bag:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1960fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best score: 0.9631268436578171\n"
     ]
    }
   ],
   "source": [
    "# 31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34fcc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10: MSE=3256.9618\n",
      "n_estimators=50: MSE=3056.4946\n",
      "n_estimators=100: MSE=2970.8632\n",
      "n_estimators=200: MSE=2995.6186\n"
     ]
    }
   ],
   "source": [
    "# 32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators_list = [10, 50, 100, 200]\n",
    "for n in n_estimators_list:\n",
    "    bagging = BaggingRegressor(n_estimators=n, random_state=42)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    y_pred = bagging.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"n_estimators={n}: MSE={mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6498ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of misclassified samples: [ 8 20 77 82]\n"
     ]
    }
   ],
   "source": [
    "# 33. Train a Random Forest Classifier and analyze misclassified samples.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mis_indices = np.where(y_pred != y_test)[0]\n",
    "print(\"Indices of misclassified samples:\", mis_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8ddd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9561\n",
      "Decision Tree Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# 34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bag = bagging.predict(X_test)\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"Bagging Accuracy: {acc_bag:.4f}\")\n",
    "print(f\"Decision Tree Accuracy: {acc_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df2ea78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7989e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('svm', SVC(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred = stacking.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2d385c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features:\n",
      "worst area: 0.1394\n",
      "worst concave points: 0.1322\n",
      "mean concave points: 0.1070\n",
      "worst radius: 0.0828\n",
      "worst perimeter: 0.0808\n"
     ]
    }
   ],
   "source": [
    "# 37. Train a Random Forest Classifier and print the top 5 most important features.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importance = rf.feature_importances_\n",
    "sorted_idx = importance.argsort()[::-1][:5]\n",
    "\n",
    "print(\"Top 5 features:\")\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{data.feature_names[idx]}: {importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b85ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9583\n",
      "Recall: 0.9718\n",
      "F1-score: 0.9650\n"
     ]
    }
   ],
   "source": [
    "# 38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3200d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=None: Accuracy=0.9649\n",
      "max_depth=5: Accuracy=0.9649\n",
      "max_depth=10: Accuracy=0.9649\n",
      "max_depth=20: Accuracy=0.9649\n",
      "max_depth=30: Accuracy=0.9649\n"
     ]
    }
   ],
   "source": [
    "# 39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "depths = [None, 5, 10, 20, 30]\n",
    "for depth in depths:\n",
    "    rf = RandomForestClassifier(max_depth=depth, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"max_depth={depth}: Accuracy={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796aa209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Bagging MSE: 3256.9618\n",
      "KNN Bagging MSE: 2990.6536\n"
     ]
    }
   ],
   "source": [
    "# 40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging_dt = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
    "bagging_dt.fit(X_train, y_train)\n",
    "y_pred_dt = bagging_dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "\n",
    "bagging_knn = BaggingRegressor(estimator=KNeighborsRegressor(), n_estimators=10, random_state=42)\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "y_pred_knn = bagging_knn.predict(X_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Decision Tree Bagging MSE: {mse_dt:.4f}\")\n",
    "print(f\"KNN Bagging MSE: {mse_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "879df129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9968400940623163\n"
     ]
    }
   ],
   "source": [
    "# 41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are the features and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance using ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49f9ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.89473684 0.93859649 0.99122807 0.96491228 1.        ]\n",
      "Mean cross-validation score: 0.9578947368421054\n"
     ]
    }
   ],
   "source": [
    "# 42: Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming X and y are the features and target variables\n",
    "bagging_classifier = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Evaluate performance using cross-validation\n",
    "cv_scores = cross_val_score(bagging_classifier, X, y, cv=5)\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean cross-validation score: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98da17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 43: Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are the features and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3724f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vivek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "# 44: Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X and y are the features and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define base classifiers\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "# Train the Stacking Classifier\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compare accuracy\n",
    "y_pred = stacking_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c25d0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample 0.5: Mean Squared Error = 0.03190409356725146\n",
      "Bootstrap Sample 0.7: Mean Squared Error = 0.03275087719298246\n",
      "Bootstrap Sample 1.0: Mean Squared Error = 0.030084795321637426\n"
     ]
    }
   ],
   "source": [
    "# 45: Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are the features and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define different levels of bootstrap samples\n",
    "bootstrap_samples = [0.5, 0.7, 1.0]\n",
    "\n",
    "for bootstrap_sample in bootstrap_samples:\n",
    "    bagging_regressor = BaggingRegressor(n_estimators=100, bootstrap_features=True, max_samples=bootstrap_sample, random_state=42)\n",
    "    bagging_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate performance\n",
    "    y_pred = bagging_regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Bootstrap Sample {bootstrap_sample}: Mean Squared Error = {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
